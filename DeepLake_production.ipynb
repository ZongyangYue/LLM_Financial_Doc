{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2Hz+PVcpYOcKBYLz9q6eY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZongyangYue/LLM_Financial_Doc/blob/main/DeepLake_production.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YColvtBMXdpK"
      },
      "outputs": [],
      "source": [
        "# install relevant packages\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip3 install langchain deeplake pypdf openai tiktoken\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import relevant packages and set up api keys and tokens\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain import OpenAI \n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAIChat\n",
        "from langchain.document_loaders import PagedPDFSplitter\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY']='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'\n",
        "os.environ['ACTIVELOOP_TOKEN']='eyJhbGciOiJIUzUxMiIsImlhdCI6MTY4NTE5NjA2NCwiZXhwIjoxNjg1NTQxNTk5fQ.eyJpZCI6Inl1ZXpvbmd5YW5nMjEwIn0.fRo3gNZGOTfzJ9klc3t9X9DEtZPQCDMhq-osEs8fw21wLOeJzYj3aFnm1QVYcGuYl25fIDG8lrsQArOjdbL3UQ'"
      ],
      "metadata": {
        "id": "IgQPif0AbJOM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define necessary helper functions\n",
        "import requests\n",
        "import tqdm\n",
        "from typing import List\n",
        "def load_reports(url):\n",
        "    pages = []\n",
        "\n",
        "    r = requests.get(url)\n",
        "    path = url.split('/')[-1]\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    loader = PagedPDFSplitter(path)\n",
        "    local_pages = loader.load_and_split()\n",
        "    pages.extend(local_pages)\n",
        "\n",
        "    return pages\n",
        "\n",
        "def run_queries(queries, qa):\n",
        "  answers = []\n",
        "  for query in queries:\n",
        "    answers.append(qa.run(query))\n",
        "  return answers\n",
        "\n",
        "def print_answers(answers):\n",
        "  for answer in answers:\n",
        "    print(answer)\n"
      ],
      "metadata": {
        "id": "F7Vfu9iqhQXw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the main function\n",
        "def analyze_accountants_report(url, activeloop_dataset_path):\n",
        "  pages = load_reports(url)\n",
        "  text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "  texts = text_splitter.split_documents(pages)\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "\n",
        "  db = DeepLake(dataset_path=activeloop_dataset_path, embedding_function=embeddings, token=os.environ['ACTIVELOOP_TOKEN'])\n",
        "  db.add_documents(texts)\n",
        "\n",
        "  qa = RetrievalQA.from_chain_type(llm=OpenAIChat(model='gpt-3.5-turbo'), chain_type='stuff', retriever=db.as_retriever())\n",
        "\n",
        "  queries = [\"What is the name of the auditor/accountant company? Look around accountant's report section\", \n",
        "           \"What is the date of the accountant's report/circular?\", \n",
        "           \"Is the acquisition approved by shareholders?\",\n",
        "           \"What is the audit fee or auditor's remuneration? Look for this around (Loss) Profit before Tax section?\",\n",
        "           \"What is the name of the company being acquired? Look for its specific name around the Definitions pages\"]\n",
        "  answers = run_queries(queries, qa)\n",
        "  print_answers(answers)"
      ],
      "metadata": {
        "id": "mYfnzaMKhTJm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first example document\n",
        "url = 'https://www1.hkexnews.hk/listedco/listconews/sehk/2023/0220/2023022000301.pdf'\n",
        "activeloop_dataset_path = \"hub://yuezongyang210/shunteng_intl2\"\n",
        "analyze_accountants_report(url, activeloop_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0zvIkGxXl7P",
        "outputId": "a70e1737-c1e8-4d29-b482-867abf331b4e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/yuezongyang210/shunteng_intl2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://yuezongyang210/shunteng_intl2 loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r\r \r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Lake Dataset in hub://yuezongyang210/shunteng_intl2 already exists, loading from the storage\n",
            "Dataset(path='hub://yuezongyang210/shunteng_intl2', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype     shape      dtype  compression\n",
            "  -------   -------   -------    -------  ------- \n",
            " embedding  generic  (99, 1536)  float32   None   \n",
            "    ids      text     (99, 1)      str     None   \n",
            " metadata    json     (99, 1)      str     None   \n",
            "   text      text     (99, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ingest: 100%|██████████| 1/1 [00:28<00:00\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:716: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://yuezongyang210/shunteng_intl2', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype      shape      dtype  compression\n",
            "  -------   -------    -------    -------  ------- \n",
            " embedding  generic  (198, 1536)  float32   None   \n",
            "    ids      text     (198, 1)      str     None   \n",
            " metadata    json     (198, 1)      str     None   \n",
            "   text      text     (198, 1)      str     None   \n",
            "The name of the auditor/accountant company is Moore Stephens CPA Limited.\n",
            "The accountant's report/circular is dated February 20, 2023.\n",
            "It is not stated in the given context whether the acquisition has been approved by shareholders or not. The circular only provides information about the EGM and the requirements for shareholder approval.\n",
            "The audit fee or auditor's remuneration is HK$6,000 for all periods listed in the context. It is mentioned in the (Loss) Profit before Tax section under \"Auditor's remuneration.\"\n",
            "The name of the company being acquired is Shunten International (Holdings) Limited, as stated under the definition for \"Company\" on the Definitions page.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second example document\n",
        "url = 'https://www1.hkexnews.hk/listedco/listconews/sehk/2019/1227/2019122700117.pdf'\n",
        "activeloop_dataset_path = \"hub://yuezongyang210/zhuhai_huafa2\"\n",
        "analyze_accountants_report(url, activeloop_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f16ZpBk7XvWo",
        "outputId": "de486a26-769e-4484-d495-6dd903bea7b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Deep Lake dataset has been successfully created!\n",
            "The dataset is private so make sure you are logged in!\n",
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/yuezongyang210/zhuhai_huafa2\n",
            "hub://yuezongyang210/zhuhai_huafa2 loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ingest: 100%|██████████| 1/1 [00:11<00:00\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:716: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://yuezongyang210/zhuhai_huafa2', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype      shape      dtype  compression\n",
            "  -------   -------    -------    -------  ------- \n",
            " embedding  generic  (312, 1536)  float32   None   \n",
            "    ids      text     (312, 1)      str     None   \n",
            " metadata    json     (312, 1)      str     None   \n",
            "   text      text     (312, 1)      str     None   \n",
            "The auditor/accountant company is PricewaterhouseCoopers, Certified Public Accountants.\n",
            "The accountant's report and circular are dated December 27, 2019.\n",
            "It is not stated in the given context whether the acquisition has been approved by shareholders or not. The letters and notices discuss the recommendation of the Independent Board Committee and the Board of Directors to vote in favor of the resolution to approve the acquisition and property management services cooperation framework agreement at the SGM. However, the actual outcome of the vote is not mentioned.\n",
            "The information provided does not contain the audit fee or auditor's remuneration.\n",
            "The company being acquired is not explicitly stated in the Definitions pages.\n"
          ]
        }
      ]
    }
  ]
}